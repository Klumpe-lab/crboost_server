# High level overview:

The biggest change so far has of course been the switch from [the collection-of-scripts wrapping relion pipeliner and schemer, executing over ssh and serving a PyQT GUI] to the ["webserver with a structured backend component"] proposed by Florian. So far this mainly has the advantage of eliminating the need to handle ssh connections (since the server already runs on the headnode) and lent us the opportunity to:
- separte the scheduling/orchestration logic from the UI components as well as move them to the browser akin to Jupyter, CryoSparc and similar resource-intesive GUI-based applications. 
- as results, centralize certain parts of the logic that were spread across stages of the job preparation.


# Some paint points in slightly more detail:

1. Injection of additional per-need parameters per job into the pipeline (things of the form `qsub_extran`).
These were previously recorded both in conf.yaml and individual jobs as some version of defaults and post-processed by the cryoboost-the-application before the `relion_schemer` call. (https://github.com/FlorianBeckOle/CryoBoost/blob/e9682d647fd12a4cb596070c53e4d4b431defa86/src/rw/librw.py#L274-L296). Currently it's handled in a similar "aliasing/de-aliasing" manner but is now centralized to one place (project creation) and can be easily extended to accommodate non-qsub related parameters from a single config file.. [ rudimentary example here ](./services/simple_computing_service.py) and [here](./services/project_service.py#66-77), but the plan is to have these as "dataclass"/pydantic models s.t we can also speic

2. `fn_exe`. The main mechanism by which the command from a particular `job.star` made its way into the eventual qsub script was "hostage" to relion_schemer. That is, each particular job type's `job.star` specified its own dedicated wrapper in the [`fn_exe`](https://github.com/FlorianBeckOle/CryoBoost/blob/e9682d647fd12a4cb596070c53e4d4b431defa86/config/Schemes/warp_tomo_prep/fsMotionAndCtf/job.star#L17) section, which according to relion's rule would be invoked and its results -- substituted for the `XXXcommandXXX` template variable in the eventual qsub. That, however, meant that the `qsub.sh` script depended on the invocation of the given script specified in the `fn_exe`, namely our bespoke "wrappers" -- `crboost_warp_fs_motion_and_ctf.py` etc. -- which, in turn necessitated a python environment to run in (hence the "satellite repo"). This indirection is eliminated by just directly building the tool speicifc command (ex. `WarpTools --create_settings foo bar..`) and doing in due time this piece of work that `relion_schemer` outsourced to the wrappers in the end. Basically, we subsume the [ former "wrappers" ](./services/pipeline_orchestrator_service.py#37-82) into our own orchestration pipeline and push upstream in the dataflow. All parameter parsing logic remains the same and is as flexible as needed and can in fact be stronger typed with a pydantic model (define allowalbe ranges for certain parameters, appropriate and constrained choices for others, datatypes at the basic etc.).

3. 